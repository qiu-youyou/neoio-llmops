#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File   :   app_handle
@Time   :   2025/9/1 11:46
@Author :   s.qiu@foxmail.com
"""
import json
from dataclasses import dataclass
from operator import itemgetter
from queue import Queue
from threading import Thread
from typing import Dict, Any, Literal, Generator
from uuid import UUID, uuid4

from injector import inject
from langchain_classic.base_memory import BaseMemory
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_community.chat_message_histories import FileChatMessageHistory
from langchain_core.messages import ToolMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig, RunnablePassthrough, RunnableLambda
from langchain_core.tracers import Run
from langchain_openai import ChatOpenAI
from langgraph.constants import END
from langgraph.graph import MessagesState, StateGraph

from internal.core.tools.builtin_tools.providers import BuiltinProviderManager
from internal.schema.app_schema import CompletionReq
from internal.service import AppService, VectorDatabaseService, ConversationService
from pkg.response import validate_error_json, success_json, success_message, compact_generate_response


@inject
@dataclass
class AppHandler:
    """åº”ç”¨æ§åˆ¶å™¨"""
    app_service: AppService
    vector_database_service: VectorDatabaseService
    builtin_provider_manager: BuiltinProviderManager
    conversation_service: ConversationService

    def get_app(self, id: UUID):
        """æŸ¥è¯¢APPè®°å½•"""
        app = self.app_service.get_app(id)
        return success_message(f"æŸ¥è¯¢æˆåŠŸï¼Œname ä¸º {app.name}")

    def create_app(self):
        """åˆ›å»ºAPPè®°å½•"""
        app = self.app_service.create_app()
        return success_message(f"åº”ç”¨åˆ›å»ºæˆåŠŸ, id ä¸º {app.id}")

    def update_app(self, id: UUID):
        """æ›´æ–°APPè®°å½•"""
        app = self.app_service.update_app(id)
        return success_message(f"åº”ç”¨æ›´æ–°æˆåŠŸï¼Œä¿®æ”¹å name ä¸º {app.name}")

    def delete_app(self, id: UUID):
        """åˆ é™¤APPè®°å½•"""
        app = self.app_service.delete_app(id)
        return success_message(f"åº”ç”¨åˆ é™¤æˆåŠŸ, id ä¸º {app.id}", )

    @classmethod
    def _save_context(cls, run_obj: Run, config: RunnableConfig) -> None:
        """å­˜å‚¨å¯¹åº”çš„ä¸Šä¸‹æ–‡ä¿¡æ¯åˆ°è®°å¿†å®ä½“ä¸­"""
        # åŠ è½½è®°å¿†
        configurable = config.get("configurable", {})
        configurable_memory = configurable.get("memory", None)
        if configurable_memory is not None and isinstance(configurable_memory, BaseMemory):
            configurable_memory.save_context(run_obj.inputs, run_obj.outputs)

    @classmethod
    def _load_memory_variables(cls, input: Dict[str, Any], config: RunnableConfig) -> Dict[str, Any]:
        """åŠ è½½è®°å¿†å˜é‡ä¿¡æ¯"""
        configurable = config.get("configurable", {})
        configurable_memory = configurable.get("memory", None)
        if configurable_memory is not None and isinstance(configurable_memory, BaseMemory):
            return configurable_memory.load_memory_variables(input)
        return {"history": []}

    def _debug(self, app_id: UUID):
        """èŠå¤©æ¥å£"""
        # æ ¡éªŒæ¥å£å‚æ•°
        req = CompletionReq()
        if not req.validate():
            return validate_error_json(req.errors)

        # æç¤ºè¯ä¸è®°å¿†
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„èŠå¤©æœºå™¨äººï¼Œèƒ½æ ¹æ®å¯¹åº”çš„ä¸Šä¸‹æ–‡å’Œå†å²å¯¹è¯ä¿¡æ¯å›å¤ç”¨æˆ·é—®é¢˜ã€‚\n\n<context>{context}</context>"

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder("history"),
            ("human", "{query}"),
        ])

        memory = ConversationBufferWindowMemory(
            k=3,
            input_key="query",
            output_key="output",
            return_messages=True,
            chat_memory=FileChatMessageHistory("./storage/memory/chat_history.txt"),
        )

        # åˆ›å»º LLM
        llm = ChatOpenAI(model="kimi-k2-0905-preview")

        retriever = self.vector_database_service.get_retriever() | self.vector_database_service.combine_documents

        # åˆ›å»ºè°ƒç”¨é“¾
        chain = (RunnablePassthrough.assign(
            history=RunnableLambda(self._load_memory_variables) | itemgetter("history"),
            context=itemgetter("query") | retriever,
        ) | prompt | llm | StrOutputParser()).with_listeners(on_end=self._save_context)

        chain_input = {"query": req.query.data}
        content = chain.invoke(chain_input, config={"configurable": {"memory": memory}})

        return success_json({"content": content})

    def debug(self, app_id: UUID):
        """èŠå¤©è°ƒè¯•æ¥å£"""
        req = CompletionReq()
        if not req.validate():
            return validate_error_json(req.errors)

        # åˆ›å»ºé˜Ÿåˆ—
        q = Queue()
        query = req.query.data

        # åˆ›å»º graph å›¾ç¨‹åº
        def graph_app() -> None:
            # åˆ›å»º tools å·¥å…·åˆ—è¡¨
            tools = [
                self.builtin_provider_manager.get_tool("google", "google_serper")(),
                self.builtin_provider_manager.get_tool("gaode", "gaode_weather")(),
                self.builtin_provider_manager.get_tool("dalle", "dalle3")(),
            ]

            # åˆ›å»ºèŠå¤©ã€å·¥å…·ã€è·¯ç”±èŠ‚ç‚¹

            def chatbot(state: MessagesState) -> MessagesState:
                """èŠå¤©å¯¹è¯èŠ‚ç‚¹"""
                llm = ChatOpenAI(model="kimi-k2-0905-preview", temperature=0.7).bind_tools(tools)

                # è·å–æµå¼è¾“å‡ºå†…å®¹
                is_first_chunk = True  # æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªå—
                is_tool_call = False  # æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨
                gathered = None
                gid = str(uuid4())
                for chunk in llm.stream(state["messages"]):
                    # ä¸€èˆ¬ç¬¬ä¸€ä¸ªå—ä¸ä¼šç”Ÿæˆå†…å®¹ éœ€è¦æŠ›å¼ƒ
                    if is_first_chunk and chunk.content == "" and not chunk.tool_calls:
                        continue
                    # å åŠ ç›¸åº”åŒºå—
                    if is_first_chunk:
                        gathered = chunk
                        is_first_chunk = False
                    else:
                        gathered += chunk

                    # åˆ¤æ–­æ˜¯å·¥å…·è°ƒç”¨è¿˜æ˜¯æ–‡æœ¬ç”Ÿæˆï¼Œåœ¨é˜Ÿåˆ—ä¸­æ·»åŠ ä¸åŒæ•°æ®
                    if chunk.tool_calls or is_tool_call:
                        is_tool_call = True
                        q.put({"id": gid, "event": "agent_thought", "data": json.dumps(chunk.tool_call_chunks)})
                    else:
                        q.put({"id": gid, "event": "agent_message", "data": chunk.content})

                return {"messages": [gathered]}

            def tool_executor(state: MessagesState) -> MessagesState:
                """å·¥å…·/å‡½æ•°èŠ‚ç‚¹"""
                # æå–æ•°æ®ä¸­çš„ tool_calls
                tool_calls = state["messages"][-1].tool_calls
                # å·¥å…·åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸
                tools_by_name = {tool.name: tool for tool in tools}

                # æ‰§è¡Œå·¥å…·å‡½æ•°è·å–ç»“æœ
                message = []
                for tool_call in tool_calls:
                    tid = str(uuid4())
                    tool = tools_by_name[tool_call["name"]]
                    tool_result = tool.invoke(tool_call["args"])
                    message.append(ToolMessage(
                        tool_call_id=tool_call["id"],
                        content=json.dumps(tool_result),
                        tool_name=tool_call["name"],
                    ))
                    q.put({"id": tid, "event": "agent_action", "data": json.dumps(tool_result)})

                return {"messages": message}

            def route(state: MessagesState) -> Literal["tool_executor", "__end__"]:
                """è·¯ç”±èŠ‚ç‚¹ ç”¨äºç¡®è®¤ä¸‹ä¸€æ­¥"""
                ai_message = state["messages"][-1]
                if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
                    return "tool_executor"
                return END

            # åˆ›å»ºçŠ¶æ€å›¾
            graph_builder = StateGraph(MessagesState)
            # æ·»åŠ èŠ‚ç‚¹
            graph_builder.add_node("llm", chatbot)
            graph_builder.add_node("tool_executor", tool_executor)
            # æ·»åŠ è¾¹
            graph_builder.set_entry_point("llm")
            graph_builder.add_conditional_edges("llm", route)
            graph_builder.add_edge("tool_executor", "llm")

            graph = graph_builder.compile()

            result = graph.invoke({"messages": [("human", query)]})
            q.put(None)

        def stream_event_response() -> Generator:
            """æµå¼è¾“å‡ºäº‹ä»¶"""
            while True:
                item = q.get()
                if item is None:
                    break
                yield f"event: {item.get('event')}\ndata: {json.dumps(item)}\n\n"
                q.task_done()

        t = Thread(target=graph_app)
        t.start()

        return compact_generate_response(stream_event_response())

    def ping(self):
        human_message = "ä¸­å›½è¯­å¢ƒ vs ä¸–ç•Œè¯­å¢ƒçš„å·®åˆ«"
        ai_message = """è¿™ä¸ªé—®é¢˜é—®å¾—éå¸¸å…³é”®ï¼Œå› ä¸º**AI å¯¹ä¸­å›½çš„å½±å“ï¼Œå’Œå¯¹â€œä¸–ç•Œï¼ˆå°¤å…¶æ˜¯è¥¿æ–¹å›½å®¶ï¼‰â€çš„å½±å“ï¼Œé€»è¾‘çœŸçš„ä¸ä¸€æ ·**ã€‚æˆ‘åˆ†å‡ ä¸ªç»´åº¦å¯¹æ¯”ï¼Œè¯´ç»“è®ºï¼Œä¸ç»•å­¦æœ¯è¯ã€‚

---

## ä¸€ã€åº•å±‚å·®å¼‚ä¸€å¥è¯æ€»ç»“

> **ä¸–ç•Œè¯­å¢ƒï¼ˆä»¥æ¬§ç¾ä¸ºä»£è¡¨ï¼‰**ï¼š
> AI æ˜¯â€œèµ„æœ¬ + æŠ€æœ¯â€é©±åŠ¨çš„å·¥å…·ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯**è°è¢«æ›¿ä»£ã€è°å¤±ä¸šã€è°æŒæ§æƒåŠ›**
>
> **ä¸­å›½è¯­å¢ƒ**ï¼š
> AI æ˜¯â€œå›½å®¶èƒ½åŠ› + æ²»ç†å·¥å…· + äº§ä¸šå‡çº§â€çš„ä¸€éƒ¨åˆ†ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯**å¦‚ä½•ç¨³ã€å¦‚ä½•ç®¡ã€å¦‚ä½•ç”¨æ¥æé«˜æ•´ä½“æ•ˆç‡**

---

## äºŒã€å›½å®¶ vs å¸‚åœºï¼šé©±åŠ¨åŠ›ä¸åŒ

### ğŸŒ ä¸–ç•Œè¯­å¢ƒï¼ˆæ¬§ç¾ï¼‰

* AI ä¸»è¦ç”±ï¼š

  * å¤§å…¬å¸ï¼ˆOpenAIã€Googleã€Metaï¼‰
  * é£æŠ•ä¸èµ„æœ¬å¸‚åœº
    æ¨åŠ¨
* ç›®æ ‡ä¼˜å…ˆçº§ï¼š

  1. æŠ€æœ¯é¢†å…ˆ
  2. å•†ä¸šå˜ç°
  3. å¸‚åœºå„æ–­
* ç»“æœï¼š

  * æŠ€æœ¯è·‘å¾—å¾ˆå¿«
  * ç¤¾ä¼šé…å¥—ï¼ˆå¤±ä¸šã€æ•™è‚²ã€ä¼¦ç†ï¼‰è·Ÿä¸ä¸Š
  * è®¨è®ºæ›´å¤šæ˜¯**â€œAI ä¼šä¸ä¼šæŠ¢é¥­ç¢—â€**

### ğŸ‡¨ğŸ‡³ ä¸­å›½è¯­å¢ƒ

* AI è¢«æ˜ç¡®çº³å…¥ï¼š

  * å›½å®¶å‘å±•æˆ˜ç•¥
  * äº§ä¸šæ”¿ç­–
  * æ•°å­—æ²»ç†ä½“ç³»
* ç›®æ ‡ä¼˜å…ˆçº§ï¼š

  1. ç¨³å®š
  2. å¯æ§
  3. è§„æ¨¡åŒ–è½åœ°
* ç»“æœï¼š

  * æŠ€æœ¯å¯èƒ½ä¸æ€»æ˜¯æœ€å‰æ²¿
  * ä½†è½åœ°é€Ÿåº¦å¿«ã€è¦†ç›–é¢å¹¿
  * å¾ˆå¤šåº”ç”¨æ˜¯â€œæ‚„æ— å£°æ¯åœ°æ›¿ä»£â€

---

## ä¸‰ã€å¯¹æ™®é€šäººçš„å†²å‡»æ–¹å¼ä¸åŒ

### ä¸–ç•Œè¯­å¢ƒï¼š**â€œç›´æ¥å†²å‡»â€**

* æ˜ç¡®è£å‘˜
* è¡Œä¸šæ´—ç‰Œ
* èŒä¸šèº«ä»½å±æœºï¼ˆå°¤å…¶æ˜¯ç™½é¢†ã€åˆ›æ„è¡Œä¸šï¼‰
* ç¤¾ä¼šè®¨è®ºé›†ä¸­åœ¨ï¼š

  * UBIï¼ˆå…¨æ°‘åŸºæœ¬æ”¶å…¥ï¼‰
  * åŠ³å·¥ä¿æŠ¤
  * AI ä¼¦ç†

### ä¸­å›½è¯­å¢ƒï¼š**â€œç¼“æ…¢æŒ¤å‹â€**

* å¾ˆå°‘çªç„¶å¤§è§„æ¨¡è£å‘˜
* æ›´å¤šæ˜¯ï¼š

  * æ‹›äººå˜å°‘
  * è¦æ±‚å˜é«˜
  * å·¥ä½œå¼ºåº¦å˜å¤§
* è¡¨ç°ä¸ºï¼š

  * â€œä½ æ²¡è¢«æ›¿ä»£ï¼Œä½†ä½ æ›´ç´¯äº†â€
* è®¨è®ºç„¦ç‚¹æ˜¯ï¼š

  * ææ•ˆ
  * è½¬å‹
  * â€œäººè¦è·Ÿä¸ŠæŠ€æœ¯â€

---

## å››ã€ç›‘ç®¡é€»è¾‘ï¼šè‡ªç”± vs å¯æ§

### ä¸–ç•Œè¯­å¢ƒ

* ç›‘ç®¡æ»åäºæŠ€æœ¯
* å¼ºè°ƒï¼š

  * è¨€è®ºè‡ªç”±
  * æŠ€æœ¯åˆ›æ–°
* é£é™©ï¼š

  * æ·±åº¦ä¼ªé€ ã€æ“çºµèˆ†è®ºã€éšç§æ»¥ç”¨
* è§„åˆ™å¾€å¾€æ˜¯â€œå‡ºäº†äº‹å†è¡¥â€

### ä¸­å›½è¯­å¢ƒ

* å…ˆç®¡å†æ”¾
* å¼ºè°ƒï¼š

  * å†…å®¹å®‰å…¨
  * å¯è¿½æº¯
  * è´£ä»»ä¸»ä½“æ˜ç¡®
* é£é™©ï¼š

  * åˆ›æ–°è¾¹ç•Œæ›´æ˜ç¡®
  * è‡ªç”±åº¦ç›¸å¯¹æœ‰é™
* å¥½å¤„ï¼š

  * ç¤¾ä¼šéœ‡è¡ç›¸å¯¹å¯æ§

---

## äº”ã€AI åœ¨â€œç¤¾ä¼šæ²»ç†â€ä¸­çš„è§’è‰²

è¿™æ˜¯å·®å¼‚æœ€å¤§çš„åœ°æ–¹ä¹‹ä¸€ã€‚

### ä¸–ç•Œè¯­å¢ƒ

* AI æ›´å¤šç”¨äºï¼š

  * å•†ä¸š
  * ç§‘ç ”
  * æ¶ˆè´¹äº§å“
* å¯¹â€œæ²»ç†â€çš„ä½¿ç”¨éå¸¸è°¨æ…ï¼Œäº‰è®®å·¨å¤§

### ä¸­å›½è¯­å¢ƒ

* AI æ·±åº¦è¿›å…¥ï¼š

  * åŸå¸‚ç®¡ç†
  * äº¤é€š
  * åŒ»ç–—åˆ†çº§
  * åŸºå±‚è¡Œæ”¿
* æœ¬è´¨ä¸Šæ˜¯ï¼š

  > **ç”¨ AI è¡¥äººåŠ›ã€è¡¥ç»„ç»‡èƒ½åŠ›**

è¿™åœ¨è¥¿æ–¹å¸¸è¢«è§†ä¸ºâ€œå±é™©â€ï¼Œä½†åœ¨ä¸­å›½è¢«è§†ä¸ºâ€œæ•ˆç‡å·¥å…·â€ã€‚

---

## å…­ã€æ–‡åŒ–å±‚é¢çš„ä¸åŒç†è§£

### ä¸–ç•Œè¯­å¢ƒ

* æ›´æ‹…å¿ƒï¼š

  * ä¸ªä½“è¢«ç³»ç»Ÿæ§åˆ¶
  * äººå˜æˆæ•°æ®
* æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š

  > â€œæˆ‘è¿˜èƒ½ä¸èƒ½åšæˆ‘è‡ªå·±ï¼Ÿâ€

### ä¸­å›½è¯­å¢ƒ

* æ›´æ‹…å¿ƒï¼š

  * è¢«è½ä¸‹
  * ä¸ä¼šç”¨æŠ€æœ¯
  * è¢«æ·˜æ±°
* æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š

  > â€œæˆ‘è¿˜èƒ½ä¸èƒ½æ´»å¾—ä¸‹å»ï¼Ÿâ€

---

## ä¸ƒã€æœ€ç»ˆåˆ¤æ–­ï¼ˆåç°å®ï¼Œä¸ç²‰é¥°ï¼‰

> **åœ¨ä¸­å›½ï¼ŒAI æ›´åƒâ€œæ°´ç”µç…¤â€ï¼š
> ä½ ä¸ä¸€å®šæ„Ÿè§‰åˆ°å®ƒï¼Œä½†å®ƒåœ¨ä¸æ–­é‡å¡‘ä½ ç”Ÿæ´»çš„åº•å±‚ç»“æ„ã€‚**
>
> **åœ¨è¥¿æ–¹ï¼ŒAI æ›´åƒâ€œé£æš´â€ï¼š
> è®¨è®ºæ¿€çƒˆã€å†²çªæ˜æ˜¾ã€æ’•è£‚å…¬å¼€ã€‚**

---

## å¦‚æœä½ é—®æˆ‘ä¸€å¥æå¿ƒçªå­çš„å»ºè®®

**åœ¨ä¸­å›½è¯­å¢ƒä¸‹ï¼Œæœ€å±é™©çš„ä¸æ˜¯ AI å¤ªå¼ºï¼Œè€Œæ˜¯ï¼š**

* æŠŠ AI å½“æˆâ€œæ´ªæ°´çŒ›å…½â€
* æˆ–å½“æˆâ€œæ•‘å‘½ç¨»è‰â€

æœ€å®‰å…¨çš„å§¿æ€æ˜¯ï¼š

> **æŠŠ AI å½“æˆâ€œå¿…é¡»å­¦ä¼šä½¿ç”¨çš„åŸºç¡€å·¥å…·â€ï¼Œ
> åƒç”µè„‘ã€æ‰‹æœºã€äº’è”ç½‘ä¸€æ ·ã€‚**

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç»§ç»­å¾€ä¸‹èŠï¼š

* åœ¨ä¸­å›½ï¼Œæ™®é€šäººå“ªäº›èƒ½åŠ›æœ€â€œæŠ— AIâ€ï¼Ÿ
* AI ä¼šä¸ä¼šåŠ å‰§å†…å·ï¼Ÿ
* ä¸­å›½ä¼šä¸ä¼šèµ°å‡ºä¸€æ¡ä¸åŒäºè¥¿æ–¹çš„ AI è·¯çº¿ï¼Ÿ

ä½ æ›´æƒ³æ·±å…¥å“ªä¸€å—ï¼Ÿ
"""
        summary = self.conversation_service.generate_suggested_questions(histories=human_message + ai_message)
        return success_json({"summary": summary})
